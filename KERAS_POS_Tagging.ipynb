{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KERAS POS-Tagging.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miweru/colab-experiments/blob/master/KERAS_POS_Tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ynvR-7D8bwss",
        "colab_type": "code",
        "outputId": "d34325a9-6386-415b-aab2-43df05b3a02f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "#Das hier sind unsere Trainingsdaten.\n",
        "! git clone https://github.com/UniversalDependencies/UD_German-GSD.git\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'UD_German-GSD' already exists and is not an empty directory.\n",
            "sample_data  Savedvecs.gz  UD_German-GSD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4AKKLaaqlOa6",
        "colab_type": "code",
        "outputId": "8e2f5f0c-9e45-4d86-fcba-04f15194fb8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 23260\n",
            "drwxr-xr-x 2 root root     4096 Dec  3 17:43 sample_data\n",
            "-rw-r--r-- 1 root root 23805972 Dec  4 22:06 Savedvecs.gz\n",
            "drwxr-xr-x 4 root root     4096 Dec  4 21:48 UD_German-GSD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9avVBCg1cQee",
        "colab_type": "code",
        "outputId": "1e545328-bd08-4b7d-b484-b542c4ee0276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3673
        }
      },
      "cell_type": "code",
      "source": [
        "for ln, line in enumerate(open(\"UD_German-GSD/de_gsd-ud-train.conllu\")):\n",
        "  if ln>100:\n",
        "    break\n",
        "  print(line)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# sent_id = train-s1\n",
            "\n",
            "# text = Sehr gute Beratung, schnelle Behebung der Probleme, so stelle ich mir Kundenservice vor.\n",
            "\n",
            "1\tSehr\tsehr\tADV\tADV\t_\t2\tadvmod\t_\t_\n",
            "\n",
            "2\tgute\tgut\tADJ\tADJA\tCase=Nom|Gender=Fem|Number=Sing\t3\tamod\t_\t_\n",
            "\n",
            "3\tBeratung\tBeratung\tNOUN\tNN\tCase=Nom|Gender=Fem|Number=Sing\t0\troot\t_\tSpaceAfter=No\n",
            "\n",
            "4\t,\t,\tPUNCT\t$,\t_\t6\tpunct\t_\t_\n",
            "\n",
            "5\tschnelle\tschnell\tADJ\tADJA\tCase=Nom|Gender=Fem|Number=Sing\t6\tamod\t_\t_\n",
            "\n",
            "6\tBehebung\tBehebung\tNOUN\tNN\tCase=Nom|Gender=Fem|Number=Sing\t3\tconj\t_\t_\n",
            "\n",
            "7\tder\tder\tDET\tART\tCase=Gen|Definite=Def|Gender=Neut|Number=Plur|PronType=Art\t8\tdet\t_\t_\n",
            "\n",
            "8\tProbleme\tProblem\tNOUN\tNN\tCase=Gen|Gender=Neut|Number=Plur\t6\tnmod\t_\tSpaceAfter=No\n",
            "\n",
            "9\t,\t,\tPUNCT\t$,\t_\t11\tpunct\t_\t_\n",
            "\n",
            "10\tso\tso\tADV\tADV\t_\t11\tadvmod\t_\t_\n",
            "\n",
            "11\tstelle\tstellen\tVERB\tVVFIN\tMood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin\t3\tparataxis\t_\t_\n",
            "\n",
            "12\tich\tich\tPRON\tPPER\tCase=Nom|Number=Sing|Person=1|PronType=Prs\t11\tnsubj\t_\t_\n",
            "\n",
            "13\tmir\tich\tPRON\tPRF\tCase=Dat|Number=Sing|Person=1|PronType=Prs|Reflex=Yes\t11\tiobj\t_\t_\n",
            "\n",
            "14\tKundenservice\tKundenservice\tNOUN\tNN\tCase=Acc|Gender=Neut|Number=Sing\t11\tobj\t_\t_\n",
            "\n",
            "15\tvor\tvor\tADP\tPTKVZ\t_\t11\tcompound:prt\t_\tSpaceAfter=No\n",
            "\n",
            "16\t.\t.\tPUNCT\t$.\t_\t3\tpunct\t_\t_\n",
            "\n",
            "\n",
            "\n",
            "# sent_id = train-s2\n",
            "\n",
            "# text = Die Kosten sind definitiv auch im Rahmen.\n",
            "\n",
            "1\tDie\tder\tDET\tART\tCase=Nom|Number=Plur|PronType=Art\t2\tdet\t_\t_\n",
            "\n",
            "2\tKosten\tKosten\tNOUN\tNN\tCase=Nom|Number=Plur\t3\tnsubj:pass\t_\t_\n",
            "\n",
            "3\tsind\tsein\tVERB\tVAFIN\tMood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin\t0\troot\t_\t_\n",
            "\n",
            "4\tdefinitiv\tdefinitiv\tADV\tADJD\t_\t3\tadvmod\t_\t_\n",
            "\n",
            "5\tauch\tauch\tADV\tADV\t_\t3\tadvmod\t_\t_\n",
            "\n",
            "6-7\tim\t_\t_\t_\t_\t_\t_\t_\t_\n",
            "\n",
            "6\tin\tin\tADP\tAPPR\t_\t8\tcase\t_\t_\n",
            "\n",
            "7\tdem\tder\tDET\tART\tCase=Dat|Definite=Def|Gender=Masc|Number=Sing|PronType=Art\t8\tdet\t_\t_\n",
            "\n",
            "8\tRahmen\tRahmen\tNOUN\tNN\tCase=Dat|Gender=Masc|Number=Sing\t3\tobl\t_\tSpaceAfter=No\n",
            "\n",
            "9\t.\t.\tPUNCT\t$.\t_\t3\tpunct\t_\t_\n",
            "\n",
            "\n",
            "\n",
            "# sent_id = train-s3\n",
            "\n",
            "# text = Nette Gespräche, klasse Ergebnis\n",
            "\n",
            "1\tNette\tnett\tADJ\tADJA\tCase=Nom|Gender=Neut|Number=Plur\t2\tamod\t_\t_\n",
            "\n",
            "2\tGespräche\tGespräch\tNOUN\tNN\tCase=Nom|Gender=Neut|Number=Plur\t0\troot\t_\tSpaceAfter=No\n",
            "\n",
            "3\t,\t,\tPUNCT\t$,\t_\t5\tpunct\t_\t_\n",
            "\n",
            "4\tklasse\tKlasse\tADJ\tADJA\t_\t5\tamod\t_\t_\n",
            "\n",
            "5\tErgebnis\tErgebnis\tNOUN\tNN\tCase=Nom|Gender=Neut|Number=Sing\t2\tconj\t_\t_\n",
            "\n",
            "\n",
            "\n",
            "# sent_id = train-s4\n",
            "\n",
            "# text = Ich bin seit längerer Zeit zur Behandlung verschiedenster \"Leiden\" in der Physiotherapieraxis \"Gaby Montag\" im Vital Center und kann ausschließlich Positives berichten!\n",
            "\n",
            "1\tIch\tich\tPRON\tPPER\tCase=Nom|Number=Sing|Person=1|PronType=Prs\t2\tnsubj\t_\t_\n",
            "\n",
            "2\tbin\tsein\tVERB\tVAFIN\tMood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin\t0\troot\t_\t_\n",
            "\n",
            "3\tseit\tseit\tADP\tAPPR\t_\t5\tcase\t_\t_\n",
            "\n",
            "4\tlängerer\tlang\tADJ\tADJA\tCase=Dat|Gender=Fem|Number=Sing\t5\tamod\t_\t_\n",
            "\n",
            "5\tZeit\tZeit\tNOUN\tNN\tCase=Dat|Gender=Fem|Number=Sing\t2\tobl\t_\t_\n",
            "\n",
            "6-7\tzur\t_\t_\t_\t_\t_\t_\t_\t_\n",
            "\n",
            "6\tzu\tzu\tADP\tAPPR\t_\t8\tcase\t_\t_\n",
            "\n",
            "7\tder\tder\tDET\tART\tCase=Dat|Definite=Def|Gender=Fem|Number=Sing|PronType=Art\t8\tdet\t_\t_\n",
            "\n",
            "8\tBehandlung\tBehandlung\tNOUN\tNN\tCase=Dat|Gender=Fem|Number=Sing\t2\tobl\t_\t_\n",
            "\n",
            "9\tverschiedenster\tverschieden\tADJ\tADJA\tCase=Gen|Gender=Neut|Number=Plur\t11\tamod\t_\t_\n",
            "\n",
            "10\t\"\t\"\tPUNCT\t$(\t_\t11\tpunct\t_\tSpaceAfter=No\n",
            "\n",
            "11\tLeiden\tLeiden\tNOUN\tNN\tCase=Gen|Gender=Neut|Number=Plur\t8\tnmod\t_\tSpaceAfter=No\n",
            "\n",
            "12\t\"\t\"\tPUNCT\t$(\t_\t11\tpunct\t_\t_\n",
            "\n",
            "13\tin\tin\tADP\tAPPR\t_\t15\tcase\t_\t_\n",
            "\n",
            "14\tder\tder\tDET\tART\tCase=Dat|Definite=Def|Gender=Fem|Number=Sing|PronType=Art\t15\tdet\t_\t_\n",
            "\n",
            "15\tPhysiotherapieraxis\tPhysiotherapieraxis\tNOUN\tNN\tCase=Dat|Gender=Fem|Number=Sing\t2\tobl\t_\t_\n",
            "\n",
            "16\t\"\t\"\tPUNCT\t$(\t_\t17\tpunct\t_\tSpaceAfter=No\n",
            "\n",
            "17\tGaby\tGaby\tPROPN\tNE\tCase=Nom|Gender=Fem|Number=Sing\t15\tappos\t_\t_\n",
            "\n",
            "18\tMontag\tMontag\tPROPN\tNE\tCase=Acc|Gender=Masc|Number=Sing\t17\tflat\t_\tSpaceAfter=No\n",
            "\n",
            "19\t\"\t\"\tPUNCT\t$(\t_\t17\tpunct\t_\t_\n",
            "\n",
            "20-21\tim\t_\t_\t_\t_\t_\t_\t_\t_\n",
            "\n",
            "20\tin\tin\tADP\tAPPR\t_\t22\tcase\t_\t_\n",
            "\n",
            "21\tdem\tder\tDET\tART\tCase=Dat|Definite=Def|Gender=Neut|Number=Sing|PronType=Art\t22\tdet\t_\t_\n",
            "\n",
            "22\tVital\tVital\tPROPN\tNN\tCase=Dat|Gender=Neut|Number=Sing\t15\tnmod\t_\t_\n",
            "\n",
            "23\tCenter\tCenter\tPROPN\tNE\tCase=Dat|Gender=Neut|Number=Sing\t22\tflat\t_\t_\n",
            "\n",
            "24\tund\tund\tCCONJ\tKON\t_\t28\tcc\t_\t_\n",
            "\n",
            "25\tkann\tkönnen\tAUX\tVMFIN\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t28\taux\t_\t_\n",
            "\n",
            "26\tausschließlich\tausschließlich\tADV\tADV\t_\t28\tadvmod\t_\t_\n",
            "\n",
            "27\tPositives\tPositive\tNOUN\tNN\tCase=Acc|Gender=Neut|Number=Sing\t28\tobj\t_\t_\n",
            "\n",
            "28\tberichten\tberichten\tVERB\tVVINF\tVerbForm=Inf\t2\tconj\t_\tSpaceAfter=No\n",
            "\n",
            "29\t!\t!\tPUNCT\t$.\t_\t2\tpunct\t_\t_\n",
            "\n",
            "\n",
            "\n",
            "# sent_id = train-s5\n",
            "\n",
            "# text = Ob bei der Terminvergabe, den Behandlungsräumen oder den individuell zugeschnittenen Trainingsplänen sind alle Mitarbeiter äußerst kompetent und flexibel.\n",
            "\n",
            "1\tOb\tob\tCCONJ\tKOUS\t_\t4\tcc\t_\t_\n",
            "\n",
            "2\tbei\tbei\tADP\tAPPR\t_\t4\tcase\t_\t_\n",
            "\n",
            "3\tder\tder\tDET\tART\tCase=Dat|Definite=Def|Gender=Fem|Number=Sing|PronType=Art\t4\tdet\t_\t_\n",
            "\n",
            "4\tTerminvergabe\tTerminvergabe\tNOUN\tNN\tCase=Dat|Gender=Fem|Number=Sing\t17\tnmod\t_\tSpaceAfter=No\n",
            "\n",
            "5\t,\t,\tPUNCT\t$,\t_\t7\tpunct\t_\t_\n",
            "\n",
            "6\tden\tder\tDET\tART\tCase=Dat|Definite=Def|Gender=Masc|Number=Plur|PronType=Art\t7\tdet\t_\t_\n",
            "\n",
            "7\tBehandlungsräumen\tBehandlungsraum\tNOUN\tNN\tCase=Dat|Gender=Masc|Number=Plur\t4\tconj\t_\t_\n",
            "\n",
            "8\toder\toder\tCCONJ\tKON\t_\t12\tcc\t_\t_\n",
            "\n",
            "9\tden\tder\tDET\tART\tCase=Dat|Definite=Def|Gender=Neut|Number=Plur|PronType=Art\t12\tdet\t_\t_\n",
            "\n",
            "10\tindividuell\tindividuell\tADV\tADJD\t_\t11\tadvmod\t_\t_\n",
            "\n",
            "11\tzugeschnittenen\tzugeschnitten\tADJ\tADJA\tCase=Dat|Gender=Masc|Number=Plur\t12\tamod\t_\t_\n",
            "\n",
            "12\tTrainingsplänen\tTrainingsplan\tNOUN\tNN\tCase=Dat|Gender=Masc|Number=Plur\t4\tconj\t_\t_\n",
            "\n",
            "13\tsind\tsein\tAUX\tVAFIN\tMood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin\t17\tcop\t_\t_\n",
            "\n",
            "14\talle\talle\tPRON\tPIAT\tCase=Nom|Definite=Ind|Gender=Masc|Number=Plur|PronType=Ind\t15\tdet\t_\t_\n",
            "\n",
            "15\tMitarbeiter\tMitarbeiter\tNOUN\tNN\tCase=Nom|Gender=Masc|Number=Plur\t17\tnsubj\t_\t_\n",
            "\n",
            "16\täußerst\täußerst\tADV\tADV\t_\t17\tadvmod\t_\t_\n",
            "\n",
            "17\tkompetent\tkompetent\tADJ\tADJD\t_\t0\troot\t_\t_\n",
            "\n",
            "18\tund\tund\tCCONJ\tKON\t_\t19\tcc\t_\t_\n",
            "\n",
            "19\tflexibel\tflexibel\tADJ\tADJD\t_\t17\tconj\t_\tSpaceAfter=No\n",
            "\n",
            "20\t.\t.\tPUNCT\t$.\t_\t17\tpunct\t_\t_\n",
            "\n",
            "\n",
            "\n",
            "# sent_id = train-s6\n",
            "\n",
            "# text = Sauberkeit, Ordnung und Freundlichkeit brauche ich hier nicht zu erwähnen, denn das gehört für mich zum Standard, der aber auch noch übertroffen wird.\n",
            "\n",
            "1\tSauberkeit\tSauberkeit\tNOUN\tNN\tCase=Nom|Gender=Fem|Number=Sing\t11\tobj\t_\tSpaceAfter=No\n",
            "\n",
            "2\t,\t,\tPUNCT\t$,\t_\t3\tpunct\t_\t_\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XcKDKVSLd1EC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "ddata=dict()\n",
        "#data=dict()\n",
        "for ln, line in enumerate(open(\"UD_German-GSD/de_gsd-ud-train.conllu\")):\n",
        "  if line.startswith(\"# sent_id\"):\n",
        "    sid=line.lstrip(\"# sent_id = \").strip()\n",
        "    #data[sid]=dict()\n",
        "    #sdata=data[sid]\n",
        "  if line.startswith(\"#\"):\n",
        "    continue\n",
        "  cont=line.split(\"\\t\")\n",
        "  if len(cont)<2:\n",
        "    continue\n",
        "  if cont[3]==\"_\":\n",
        "    continue\n",
        "  #sdata[cont[0]]={\"word\":cont[1].lower(),\"tag\":cont[3]}\n",
        "  ddata[sid+\"_\"+\"{0:03}\".format(int(cont[0]))]={\"lineNumber\":int(cont[0]),\"word_l\":cont[1].lower(),\"tag\":cont[3]}\n",
        "  \n",
        "for ln, line in enumerate(open(\"UD_German-GSD/de_gsd-ud-dev.conllu\")):\n",
        "  if line.startswith(\"# sent_id\"):\n",
        "    sid=line.lstrip(\"# sent_id = \").strip()\n",
        "    #data[sid]=dict()\n",
        "    #sdata=data[sid]\n",
        "  if line.startswith(\"#\"):\n",
        "    continue\n",
        "  cont=line.split(\"\\t\")\n",
        "  if len(cont)<2:\n",
        "    continue\n",
        "  if cont[3]==\"_\":\n",
        "    continue\n",
        "  #sdata[cont[0]]={\"word\":cont[1].lower(),\"tag\":cont[3]}\n",
        "  ddata[sid+\"_\"+\"{0:03}\".format(int(cont[0]))]={\"lineNumber\":int(cont[0]),\"word_l\":cont[1].lower(),\"tag\":cont[3]}\n",
        "\n",
        "#eval=dict()\n",
        "for ln, line in enumerate(open(\"UD_German-GSD/de_gsd-ud-test.conllu\")):\n",
        "  if line.startswith(\"# sent_id\"):\n",
        "    sid=line.lstrip(\"# sent_id = \").strip()\n",
        "    #data[sid]=dict()\n",
        "    #sdata=data[sid]\n",
        "  if line.startswith(\"#\"):\n",
        "    continue\n",
        "  cont=line.split(\"\\t\")\n",
        "  if len(cont)<2:\n",
        "    continue\n",
        "  if cont[3]==\"_\":\n",
        "    continue\n",
        "  #sdata[cont[0]]={\"word\":cont[1].lower(),\"tag\":cont[3]}\n",
        "  ddata[sid+\"_\"+\"{0:03}\".format(int(cont[0]))]={\"lineNumber\":int(cont[0]),\"word_l\":cont[1].lower(),\"tag\":cont[3]}\n",
        "myframe=pd.DataFrame(ddata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kYop51JjgWFs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uWeSVBk_hxUv",
        "colab_type": "code",
        "outputId": "a17916cc-29f0-4778-a6e4-62234d8ebeaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "cell_type": "code",
      "source": [
        "myframe"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-s100_001</th>\n",
              "      <th>-s100_002</th>\n",
              "      <th>-s100_003</th>\n",
              "      <th>-s100_004</th>\n",
              "      <th>-s100_005</th>\n",
              "      <th>-s100_006</th>\n",
              "      <th>-s100_007</th>\n",
              "      <th>-s100_008</th>\n",
              "      <th>-s100_009</th>\n",
              "      <th>-s100_010</th>\n",
              "      <th>...</th>\n",
              "      <th>v-s9_006</th>\n",
              "      <th>v-s9_007</th>\n",
              "      <th>v-s9_008</th>\n",
              "      <th>v-s9_009</th>\n",
              "      <th>v-s9_010</th>\n",
              "      <th>v-s9_011</th>\n",
              "      <th>v-s9_012</th>\n",
              "      <th>v-s9_013</th>\n",
              "      <th>v-s9_014</th>\n",
              "      <th>v-s9_015</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>lineNumber</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tag</th>\n",
              "      <td>DET</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>AUX</td>\n",
              "      <td>ADV</td>\n",
              "      <td>X</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>AUX</td>\n",
              "      <td>ADV</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>...</td>\n",
              "      <td>PRON</td>\n",
              "      <td>AUX</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>ADP</td>\n",
              "      <td>DET</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td>DET</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>PUNCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_l</th>\n",
              "      <td>die</td>\n",
              "      <td>ausstattung</td>\n",
              "      <td>ist</td>\n",
              "      <td>sehr</td>\n",
              "      <td>spartanisch.das</td>\n",
              "      <td>zimmer</td>\n",
              "      <td>war</td>\n",
              "      <td>sehr</td>\n",
              "      <td>klein</td>\n",
              "      <td>.</td>\n",
              "      <td>...</td>\n",
              "      <td>ich</td>\n",
              "      <td>bin</td>\n",
              "      <td>begeistert</td>\n",
              "      <td>von</td>\n",
              "      <td>der</td>\n",
              "      <td>auswahl</td>\n",
              "      <td>und</td>\n",
              "      <td>der</td>\n",
              "      <td>qualität</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 292788 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           -s100_001    -s100_002 -s100_003 -s100_004        -s100_005  \\\n",
              "lineNumber         1            2         3         4                5   \n",
              "tag              DET         NOUN       AUX       ADV                X   \n",
              "word_l           die  ausstattung       ist      sehr  spartanisch.das   \n",
              "\n",
              "           -s100_006 -s100_007 -s100_008 -s100_009 -s100_010   ...     \\\n",
              "lineNumber         6         7         8         9        10   ...      \n",
              "tag             NOUN       AUX       ADV       ADJ     PUNCT   ...      \n",
              "word_l        zimmer       war      sehr     klein         .   ...      \n",
              "\n",
              "           v-s9_006 v-s9_007    v-s9_008 v-s9_009 v-s9_010 v-s9_011 v-s9_012  \\\n",
              "lineNumber        6        7           8        9       10       11       12   \n",
              "tag            PRON      AUX         ADJ      ADP      DET     NOUN    CCONJ   \n",
              "word_l          ich      bin  begeistert      von      der  auswahl      und   \n",
              "\n",
              "           v-s9_013  v-s9_014 v-s9_015  \n",
              "lineNumber       13        14       15  \n",
              "tag             DET      NOUN    PUNCT  \n",
              "word_l          der  qualität        .  \n",
              "\n",
              "[3 rows x 292788 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "5jZcDWpeljck",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Cs_so9pnsJ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Gut, wandeln wir das mal in Sequenzen von Sätzen um:\n",
        "target=[]\n",
        "train=[]\n",
        "md=[]\n",
        "mt=[]\n",
        "\n",
        "for ln in myframe:\n",
        "  mo=myframe[ln]\n",
        "  if mo[\"lineNumber\"]==1:\n",
        "    if md:\n",
        "      target.append(mt)\n",
        "      train.append(md)\n",
        "    md=[]\n",
        "    mt=[]\n",
        "  md.append(mo[\"word_l\"])\n",
        "  mt.append(mo[\"tag\"])\n",
        "md.append(mo[\"word_l\"])\n",
        "mt.append(mo[\"tag\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SXWGg7nhEpi2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"etarget=[]\n",
        "etrain=[]\n",
        "md=[]\n",
        "mt=[]\n",
        "\n",
        "for ln in evaluation:\n",
        "  mo=evaluation[ln]\n",
        "  if mo[\"lineNumber\"]==1:\n",
        "    if md:\n",
        "      etarget.append(mt)\n",
        "      etrain.append(md)\n",
        "    md=[]\n",
        "    mt=[]\n",
        "  md.append(mo[\"word_l\"])\n",
        "  mt.append(mo[\"tag\"])\n",
        "etarget.append(mt)\n",
        "etrain.append(md)\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "be0Z8wMZrBf_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#del(myframe)\n",
        "\n",
        "#del(evaluation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rK-nN7XSp2ML",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#myframe[ln]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ib9KyHvOtA46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "outputId": "241008ca-579f-448a-bc38-8adf8e693f00"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Das hier sind Schritte, um das Modell so klein zu machen, dass es auch in den Arbeitsspeicher von Colab passt.\n",
        "Dafür lade ich es, und schreibe jedes enthaltene Wort in einen neuen Vektor\n",
        "Im nächsten durchlauf können wir dann die Embedding Matrix aus den Savedvecs erstellen\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "if 1==1:\n",
        "  !pip install gensim\n",
        "  from gensim.models.keyedvectors import KeyedVectors \n",
        "\n",
        "  wordset={word for sentence in train for word in sentence}\n",
        "  !wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/word-vectors-v2/cc.de.300.vec.gz\n",
        "  model=KeyedVectors.load_word2vec_format(\"cc.de.300.vec.gz\",binary=False)\n",
        "  !rm cc.de.300.* \n",
        "  mymodel=KeyedVectors(300)\n",
        "  for word in wordset:\n",
        "    if word in model:\n",
        "      mymodel.add(word, model[word])\n",
        "  del(model)\n",
        "  mymodel.save(\"Savedvecs.gz\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/a4/d10c0acc8528d838cda5eede0ee9c784caa598dbf40bd0911ff8d067a7eb/gensim-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (23.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 23.6MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Collecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/1f/6f27e3682124de63ac97a0a5876da6186de6c19410feab66c1543afab055/smart_open-1.7.1.tar.gz\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 15.1MB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/e4/78a78e42a98ca242ec4ef820b07d8e951f96bd7cc31f67ce11a93e0909f6/boto3-1.9.59-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 26.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.11.29)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting botocore<1.13.0,>=1.12.59 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/cf/71dfc14692883aaf709bc1098a56770173a760a14b0b1cb74471609181be/botocore-1.12.59-py2.py3-none-any.whl (5.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.1MB 6.4MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 21.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.59->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Collecting docutils>=0.10 (from botocore<1.13.0,>=1.12.59->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 23.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/23/00/44/e5b939f7a80c04e32297dbd6d96fa3065af89ecf57e2b5f89f\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.49.0 boto3-1.9.59 botocore-1.12.59 bz2file-0.98 docutils-0.14 gensim-3.6.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.7.1\n",
            "--2018-12-05 10:03:23--  https://s3-us-west-1.amazonaws.com/fasttext-vectors/word-vectors-v2/cc.de.300.vec.gz\n",
            "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.24.33\n",
            "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.24.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1278030050 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.de.300.vec.gz’\n",
            "\n",
            "cc.de.300.vec.gz    100%[===================>]   1.19G  17.0MB/s    in 72s     \n",
            "\n",
            "2018-12-05 10:04:36 (16.9 MB/s) - ‘cc.de.300.vec.gz’ saved [1278030050/1278030050]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Uz5tWcDtDg0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "9000b985-9308-4a7c-bcaf-1f6220d33f79"
      },
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.58)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.10.15)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.58 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.58)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.58->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.58->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A-qwtxd1tutl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XbE8GzJLt3D-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eY68CguSz5uf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PUeYnNhFuq-q",
        "colab_type": "code",
        "outputId": "5646540a-2c2d-4496-ff45-c30a8634989c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d28f8bda2dc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwordset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmymodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'wordset' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "l_GSAcCPu68J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#mymodel.save(\"Savedvecs.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oHns0xj1zmmj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WxiApBv7oBU_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#line"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nz8LdUI5tmyr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "KDW"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sJgr4tYCmkaN",
        "colab_type": "code",
        "outputId": "6b67dc8c-e9c0-4588-f7a3-9306baeb6230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "tGHbxP1RlnBN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "99dcae7b-90dd-49ed-b600-472dde893821"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer=keras.preprocessing.text.Tokenizer(filter=\"\") #NEU\n",
        "tokenizer.fit_on_texts(train)\n",
        "X1=tokenizer.texts_to_sequences(train)\n",
        "#EX=tokenizer.texts_to_sequences(etrain)\n",
        "#del(train)\n",
        "#del(etrain)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-93fcb15f5f52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#NEU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#EX=tokenizer.texts_to_sequences(etrain)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_words, filters, lower, split, char_level, oov_token, document_count, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mnum_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nb_words'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized keyword arguments: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unrecognized keyword arguments: {'filter': ''}"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fsL94d3s6NiQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seqlength=max([len(item) for item in X1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rg-_Nwmv6Y1s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAX_SEQUENCE_LENGTH=40\n",
        "X1=keras.preprocessing.sequence.pad_sequences(X1, maxlen=MAX_SEQUENCE_LENGTH, padding=\"pre\",truncating= 'post')\n",
        "#EX=keras.preprocessing.sequence.pad_sequences(EX, maxlen=MAX_SEQUENCE_LENGTH, padding=\"pre\",truncating= 'post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eQs3zYq_XPrV",
        "colab_type": "code",
        "outputId": "fdecf647-cc59-4d73-978e-322bab10529e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X1.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15589, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "H8aivAfMSEX6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzzhLeJhSEUm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_baskets=[list() for i in range(MAX_SEQUENCE_LENGTH)]\n",
        "#AuxilaryInputs\n",
        "for text in train:\n",
        "  for i in range(MAX_SEQUENCE_LENGTH):\n",
        "    if len(text)<=i:\n",
        "      input_baskets[i].append(\"_\")\n",
        "    else:\n",
        "      input_baskets[i].append(text[i])\n",
        "#Nun sollten alle baskets gleich lang sein"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OsB2y-YwUrMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for basket in input_baskets:\n",
        "  print(len(basket))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ts0T8FQeXliX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "702c534b-ae80-4b48-b808-ece12f94289f"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'_'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "p2ib-BwHSER2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "aux_tokenizer=keras.preprocessing.text.Tokenizer(char_level=True,filters=\"\") #Hier brauchen wir die buchstabeneinstellung\n",
        "aux_tokenizer.fit_on_texts(train)\n",
        "auxseq=[pad_sequences(aux_tokenizer.texts_to_sequences(basket), maxlen=20, padding=\"pre\",truncating='pre') for basket in input_baskets]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JRMczprWSEO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b81bb652-afab-4dd9-926e-ae32d340eb5f"
      },
      "cell_type": "code",
      "source": [
        "auxseq[2][2]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0, 3444, 4954, 6730,  290,  832], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "1GapYZrySEHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba1aebf1-1995-419c-e7f8-fb61b461cc55"
      },
      "cell_type": "code",
      "source": [
        "len(aux_tokenizer.word_index)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50490"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "57yd_fp9d0nb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g20eWXNbx7BH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "targetTokenizer=keras.preprocessing.text.Tokenizer()\n",
        "targetTokenizer.fit_on_texts(target)\n",
        "Y=targetTokenizer.texts_to_sequences(target)\n",
        "#EY=targetTokenizer.texts_to_sequences(etarget)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bKH6EFG3m_aN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ctarget=targetTokenizer.texts_to_sequences(target+etarget)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oTblrpbknpoL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Y=ctarget[:len(target)]\n",
        "#EY=ctarget[len(target):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "66Eb_JqOn2tb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6eiTIkwzeVCn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "b36d9d49-aa4d-4313-a9e1-605369e08d4c"
      },
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-de29cf719ad1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "OOhQDa4QAD1N",
        "colab_type": "code",
        "outputId": "d10baac2-f8c5-448b-dc2d-b17305fb6bfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "numoftags=len({pos for sentence in target for pos in sentence})\n",
        "print(numoftags)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-ziGDMVNnOaC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a7ae5f8e-3ee8-4da7-da32-f009cb787f40"
      },
      "cell_type": "code",
      "source": [
        "#print(len({pos for sentence in etarget for pos in sentence}))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_tj47HWPewJv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Y=np.array([[i==num for i in range(numoftags)] for sentence in Y for num in sentence],dtype=np.bool)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UfICJRYrfPM0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#EY=np.array([[i==num for i in range(numoftags)] for sentence in EY for num in sentence],dtype=np.bool)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tUk9KoJ07Q1b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y=keras.preprocessing.sequence.pad_sequences(Y, maxlen=MAX_SEQUENCE_LENGTH, padding=\"pre\",truncating= 'post')\n",
        "#EY=keras.preprocessing.sequence.pad_sequences(EY, maxlen=MAX_SEQUENCE_LENGTH, padding=\"pre\",truncating= 'post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lsfq6jAehFw8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4bNV8Twof-b9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.bool"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vc3PqImkeDGd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BMxZtqMqjbPt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y=to_categorical(Y, num_classes=17)\n",
        "#EY=to_categorical(EY, num_classes=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ryMTvumK7Vj-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ddd72aa6-fb7c-4878-b781-c04b0ff373ab"
      },
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15589, 20, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "n0_kwoJ-hNB5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SmErfuLfdVXO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EY.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dbx9Et4tyg6r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A--HWRtFy703",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1vzvgsfmzyCT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "#import gensim.models.keyedvectors as kv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wnZfrHXXoeJQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!rm cc.de.300.*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "orXQo3Gdz_vu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model=KeyedVectors.load_word2vec_format(\"cc.de.300.vec.gz\",binary=False)\n",
        "#model=KeyedVectors.load_word2vec_format(\"https://s3-us-west-1.amazonaws.com/fasttext-vectors/word-vectors-v2/cc.de.300.vec.gz\",binary=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3atcP_bHEK28",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#del(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZqL8NSkqKULU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights=np.random.random((5,30))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JF3htyf4KWTQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "354d142c-e72e-4dde-c059-c6547d75aa9e"
      },
      "cell_type": "code",
      "source": [
        "model"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.training.Model at 0x7fd18a4a33c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "Qe8Sg7_Fp-Yr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors \n",
        "gmodel=KeyedVectors.load(\"Savedvecs.gz\")\n",
        "weights=np.random.random((len(tokenizer.word_index)+1,300))\n",
        "for token in tokenizer.word_index:\n",
        "  if token in gmodel:\n",
        "    weights[tokenizer.word_index[token]]=gmodel[token]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nna1wYyRaTPq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "123726c6-3e07-4347-f6af-1d0a300d9bfe"
      },
      "cell_type": "code",
      "source": [
        "weights.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50491, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "Jp_zIkUeKkRY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "c4753602-8351-4cd1-8cdb-7f2f07678686"
      },
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.32606257,  0.31952443,  0.5724918 , ...,  0.61112887,\n",
              "         0.14428032,  0.63668434],\n",
              "       [-0.0257    ,  0.0093    , -0.0562    , ...,  0.0404    ,\n",
              "        -0.0495    , -0.0133    ],\n",
              "       [-0.0354    , -0.0088    , -0.018     , ..., -0.0606    ,\n",
              "        -0.1096    ,  0.0739    ],\n",
              "       ...,\n",
              "       [ 0.85787064,  0.01113347,  0.19147647, ...,  0.44606168,\n",
              "         0.5597976 ,  0.06696565],\n",
              "       [ 0.8124987 ,  0.75546648,  0.32687834, ...,  0.02963436,\n",
              "         0.53246644,  0.51197454],\n",
              "       [ 0.0064    , -0.0098    ,  0.0024    , ...,  0.01      ,\n",
              "        -0.0088    ,  0.0015    ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "6KNfmKBE0oxW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pMKyQHcDqHN9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#embedding=model.get_keras_embedding()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KHvXAw8eBJrY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gDz8yHWaPwg8",
        "colab_type": "code",
        "outputId": "34a9de2f-7046-4a0b-da87-8f058fb3d755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2424
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, Flatten\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, TimeDistributed, Bidirectional\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "#embedded_sequences = embedding(sequence_input)\n",
        "embedded_sequences=Embedding(50491,300, weights=[weights],mask_zero=True)(sequence_input)\n",
        "x = Bidirectional(LSTM(100,return_sequences=True))(embedded_sequences)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Bidirectional(LSTM(128,return_sequences=True))(x)\n",
        "embed2= Embedding(50491, output_dim=700,mask_zero=True)(sequence_input)\n",
        "x2= Bidirectional(LSTM(128,return_sequences=True))(embed2)\n",
        "x2 = Dropout(0.5)(x2)\n",
        "x2= Bidirectional(LSTM(128,return_sequences=True))(x2)\n",
        "x = keras.layers.concatenate([x, x2])\n",
        "x = Dropout(0.5)(x)\n",
        "x = Bidirectional(LSTM(128,return_sequences=True))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Bidirectional(LSTM(64,return_sequences=True))(x)\n",
        "preds = TimeDistributed(Dense(numoftags+1,activation=\"softmax\"))(x)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "model.fit(X1, Y, epochs=100, batch_size=256, validation_split=0.1)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14030 samples, validate on 1559 samples\n",
            "Epoch 1/100\n",
            "14030/14030 [==============================] - 59s 4ms/step - loss: 2.1248 - acc: 0.2847 - val_loss: 1.4884 - val_acc: 0.5040\n",
            "Epoch 2/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.8932 - acc: 0.7182 - val_loss: 0.5492 - val_acc: 0.8394\n",
            "Epoch 3/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.3788 - acc: 0.8904 - val_loss: 0.3376 - val_acc: 0.9025\n",
            "Epoch 4/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.2363 - acc: 0.9355 - val_loss: 0.2868 - val_acc: 0.9171\n",
            "Epoch 5/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.1768 - acc: 0.9518 - val_loss: 0.3219 - val_acc: 0.9059\n",
            "Epoch 6/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.1470 - acc: 0.9588 - val_loss: 0.2731 - val_acc: 0.9218\n",
            "Epoch 7/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.1247 - acc: 0.9647 - val_loss: 0.2995 - val_acc: 0.9168\n",
            "Epoch 8/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.1083 - acc: 0.9694 - val_loss: 0.3073 - val_acc: 0.9168\n",
            "Epoch 9/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0913 - acc: 0.9742 - val_loss: 0.3040 - val_acc: 0.9207\n",
            "Epoch 10/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0794 - acc: 0.9777 - val_loss: 0.3158 - val_acc: 0.9200\n",
            "Epoch 11/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0672 - acc: 0.9809 - val_loss: 0.3379 - val_acc: 0.9167\n",
            "Epoch 12/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0590 - acc: 0.9835 - val_loss: 0.3630 - val_acc: 0.9144\n",
            "Epoch 13/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.0510 - acc: 0.9856 - val_loss: 0.3666 - val_acc: 0.9165\n",
            "Epoch 14/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0452 - acc: 0.9874 - val_loss: 0.3822 - val_acc: 0.9170\n",
            "Epoch 15/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0382 - acc: 0.9891 - val_loss: 0.3927 - val_acc: 0.9172\n",
            "Epoch 16/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0334 - acc: 0.9905 - val_loss: 0.4149 - val_acc: 0.9147\n",
            "Epoch 17/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0303 - acc: 0.9917 - val_loss: 0.4398 - val_acc: 0.9106\n",
            "Epoch 18/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0266 - acc: 0.9925 - val_loss: 0.4839 - val_acc: 0.9086\n",
            "Epoch 19/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0235 - acc: 0.9933 - val_loss: 0.4511 - val_acc: 0.9147\n",
            "Epoch 20/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0211 - acc: 0.9941 - val_loss: 0.4518 - val_acc: 0.9150\n",
            "Epoch 21/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0194 - acc: 0.9944 - val_loss: 0.4848 - val_acc: 0.9120\n",
            "Epoch 22/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0175 - acc: 0.9949 - val_loss: 0.4692 - val_acc: 0.9162\n",
            "Epoch 23/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0161 - acc: 0.9953 - val_loss: 0.4991 - val_acc: 0.9117\n",
            "Epoch 24/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0145 - acc: 0.9959 - val_loss: 0.5259 - val_acc: 0.9115\n",
            "Epoch 25/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0132 - acc: 0.9961 - val_loss: 0.5406 - val_acc: 0.9114\n",
            "Epoch 26/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0114 - acc: 0.9966 - val_loss: 0.5478 - val_acc: 0.9103\n",
            "Epoch 27/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0108 - acc: 0.9968 - val_loss: 0.5440 - val_acc: 0.9119\n",
            "Epoch 28/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.5382 - val_acc: 0.9135\n",
            "Epoch 29/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.0098 - acc: 0.9972 - val_loss: 0.5780 - val_acc: 0.9094\n",
            "Epoch 30/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.0086 - acc: 0.9975 - val_loss: 0.5667 - val_acc: 0.9110\n",
            "Epoch 31/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.0078 - acc: 0.9977 - val_loss: 0.5701 - val_acc: 0.9119\n",
            "Epoch 32/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.0077 - acc: 0.9977 - val_loss: 0.5744 - val_acc: 0.9130\n",
            "Epoch 33/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.0072 - acc: 0.9979 - val_loss: 0.6052 - val_acc: 0.9108\n",
            "Epoch 34/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.0073 - acc: 0.9978 - val_loss: 0.5903 - val_acc: 0.9117\n",
            "Epoch 35/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.6146 - val_acc: 0.9071\n",
            "Epoch 36/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.0063 - acc: 0.9980 - val_loss: 0.5968 - val_acc: 0.9130\n",
            "Epoch 37/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.6275 - val_acc: 0.9092\n",
            "Epoch 38/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.6157 - val_acc: 0.9109\n",
            "Epoch 39/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.6449 - val_acc: 0.9104\n",
            "Epoch 40/100\n",
            "14030/14030 [==============================] - 49s 4ms/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.6170 - val_acc: 0.9123\n",
            "Epoch 41/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.6839 - val_acc: 0.9054\n",
            "Epoch 42/100\n",
            "14030/14030 [==============================] - 49s 3ms/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.6298 - val_acc: 0.9121\n",
            "Epoch 43/100\n",
            " 7168/14030 [==============>...............] - ETA: 22s - loss: 0.0033 - acc: 0.9990"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-8c2fcf6249ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "UendiMKM54V4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"from keras.models import Sequential\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, Flatten\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, TimeDistributed, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(dtype='int32',tensor=X1))\n",
        "model.add(embedding)\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(300, 3, padding='valid',activation='relu',strides=2))\n",
        "model.add(Conv1D(150, 3, padding='valid',activation='relu',strides=2))\n",
        "model.add(Conv1D(75, 3, padding='valid',activation='relu',strides=2))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(TimeDistributed(Dense(150,activation='sigmoid')))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(TimeDistributed(Dense(numoftags,activation='sigmoid')))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
        "\n",
        "model.summary()\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RuzlhviHHJuv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X1.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-FtRylu6BCKw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#keras.layers.TimeDistributed()\n",
        "model_1 = Sequential()\n",
        "model_1.add(Input((50,)))\n",
        "model_1.add(embedding(X1))\n",
        "model_1.add(Bidirectional(LSTM(256,return_sequences=True)))\n",
        "model_1.add(Bidirectional(LSTM(256,return_sequences=True)))\n",
        "model_1.add(TimeDistributed(Dense(250)))\n",
        "model_1.add(Dropout(0.2))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(TimeDistributed(Dense(numoftags+1,activation=\"softmax\")))\n",
        "#model_1.add(Activation('sigmoid'))\n",
        "model_1.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
        "model_1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bcyFohx_CY_D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(x_train, y_train)#, validation_data=(x_val, y_val), epochs=2, batch_size=128)\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zgl5zpAyCkDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_1.fit(X1, Y, validation_data=(EX, EY), epochs=100, batch_size=128)\n",
        "score = model_1.evaluate(EX, EY, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jgnB6ofrWX5-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#for slice in Y:\n",
        " ä print(slice.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6u4-BPUz0N7a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VrOTUnjmr6Ga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K-lih8hOrfOx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X1=tokenizer.sequences_to_matrix(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yp2cSHcymHj8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Verwenden wir lieber mal testweise ein BiLSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bXWr2Vb6gaDm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1QsVxDAaf_51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2447
        },
        "outputId": "f077747f-c9ed-4ef3-d950-89a08b4968de"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_23 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_24 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_25 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_26 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_27 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_28 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_29 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_30 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_31 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_32 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_33 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_34 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_35 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_36 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_37 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_38 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_39 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_40 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_41 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_42 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_43 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 20, 300)      15147300    input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 20, 30)       1514700     input_24[0][0]                   \n",
            "                                                                 input_25[0][0]                   \n",
            "                                                                 input_26[0][0]                   \n",
            "                                                                 input_27[0][0]                   \n",
            "                                                                 input_28[0][0]                   \n",
            "                                                                 input_29[0][0]                   \n",
            "                                                                 input_30[0][0]                   \n",
            "                                                                 input_31[0][0]                   \n",
            "                                                                 input_32[0][0]                   \n",
            "                                                                 input_33[0][0]                   \n",
            "                                                                 input_34[0][0]                   \n",
            "                                                                 input_35[0][0]                   \n",
            "                                                                 input_36[0][0]                   \n",
            "                                                                 input_37[0][0]                   \n",
            "                                                                 input_38[0][0]                   \n",
            "                                                                 input_39[0][0]                   \n",
            "                                                                 input_40[0][0]                   \n",
            "                                                                 input_41[0][0]                   \n",
            "                                                                 input_42[0][0]                   \n",
            "                                                                 input_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_13 (Bidirectional (None, 20, 40)       51360       embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_15 (Bidirectional (None, 20, 40)       8160        embedding_6[0][0]                \n",
            "                                                                 embedding_6[1][0]                \n",
            "                                                                 embedding_6[2][0]                \n",
            "                                                                 embedding_6[3][0]                \n",
            "                                                                 embedding_6[4][0]                \n",
            "                                                                 embedding_6[5][0]                \n",
            "                                                                 embedding_6[6][0]                \n",
            "                                                                 embedding_6[7][0]                \n",
            "                                                                 embedding_6[8][0]                \n",
            "                                                                 embedding_6[9][0]                \n",
            "                                                                 embedding_6[10][0]               \n",
            "                                                                 embedding_6[11][0]               \n",
            "                                                                 embedding_6[12][0]               \n",
            "                                                                 embedding_6[13][0]               \n",
            "                                                                 embedding_6[14][0]               \n",
            "                                                                 embedding_6[15][0]               \n",
            "                                                                 embedding_6[16][0]               \n",
            "                                                                 embedding_6[17][0]               \n",
            "                                                                 embedding_6[18][0]               \n",
            "                                                                 embedding_6[19][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 20, 40)       0           bidirectional_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 20, 800)      0           bidirectional_15[0][0]           \n",
            "                                                                 bidirectional_15[1][0]           \n",
            "                                                                 bidirectional_15[2][0]           \n",
            "                                                                 bidirectional_15[3][0]           \n",
            "                                                                 bidirectional_15[4][0]           \n",
            "                                                                 bidirectional_15[5][0]           \n",
            "                                                                 bidirectional_15[6][0]           \n",
            "                                                                 bidirectional_15[7][0]           \n",
            "                                                                 bidirectional_15[8][0]           \n",
            "                                                                 bidirectional_15[9][0]           \n",
            "                                                                 bidirectional_15[10][0]          \n",
            "                                                                 bidirectional_15[11][0]          \n",
            "                                                                 bidirectional_15[12][0]          \n",
            "                                                                 bidirectional_15[13][0]          \n",
            "                                                                 bidirectional_15[14][0]          \n",
            "                                                                 bidirectional_15[15][0]          \n",
            "                                                                 bidirectional_15[16][0]          \n",
            "                                                                 bidirectional_15[17][0]          \n",
            "                                                                 bidirectional_15[18][0]          \n",
            "                                                                 bidirectional_15[19][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_14 (Bidirectional (None, 20, 40)       9760        dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_16 (Bidirectional (None, 20, 256)      951296      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 20, 296)      0           bidirectional_14[0][0]           \n",
            "                                                                 bidirectional_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 20, 296)      0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_17 (Bidirectional (None, 20, 256)      435200      dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 20, 256)      0           bidirectional_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_18 (Bidirectional (None, 20, 128)      164352      dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 20, 17)       2193        bidirectional_18[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 18,284,321\n",
            "Trainable params: 18,284,321\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b7cC35qLf3_n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#AUXMODEL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YUW7oLM4RRJq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#del(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qyDwi-V1S20x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import RepeatVector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mVLc-jMJfyyt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "55d90505-db90-4157-ef5f-dc3186164f93"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, Flatten\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, TimeDistributed, Bidirectional\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences=Embedding(50491,300, weights=[weights],mask_zero=True)(sequence_input)\n",
        "x = Bidirectional(LSTM(100,return_sequences=True))(embedded_sequences)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Bidirectional(LSTM(100,return_sequences=True))(x) # ich habe die beiden mal deutlich reduziert\n",
        "\n",
        "aux_inputs=[Input(shape=(20,), dtype=\"int32\") for i in range(20)]\n",
        "aux_embedding=Embedding(len(aux_tokenizer.word_index),50,mask_zero=True)\n",
        "aux_embedded=[aux_embedding(inp) for inp in aux_inputs]\n",
        "aux_lstm=LSTM(100)#,return_sequences=True)\n",
        "aux_x = [Dropout(0.3)(aux_lstm(vals)) for vals in aux_embedded]\n",
        "x2=keras.layers.concatenate(aux_x)\n",
        "x2=Dense(4000)(x2)\n",
        "x2=Dense(300)(x2)\n",
        "x2=RepeatVector(20)(x2)\n",
        "#x2=Bidirectional(LSTM(128,return_sequences=True))(x2)\n",
        "x = keras.layers.concatenate([x, x2])\n",
        "#x=x2\n",
        "x = Dropout(0.5)(x)\n",
        "x = Bidirectional(LSTM(256,return_sequences=True))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Bidirectional(LSTM(128,return_sequences=True))(x)\n",
        "preds = TimeDistributed(Dense(numoftags+1,activation=\"softmax\"))(x)\n",
        "\n",
        "model = Model([sequence_input]+aux_inputs, preds)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "model.fit([X1]+auxseq, Y, epochs=100, batch_size=128, validation_split=0.1)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-4fe32f4eb7ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0maux_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mauxseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected time_distributed_2 to have 3 dimensions, but got array with shape (15589, 20, 17, 17)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xQHQDv2udXqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d9ab862f-cb6a-46cc-bdc4-a564898a25b4"
      },
      "cell_type": "code",
      "source": [
        "[1]+[2,3entstehen]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "hHx73yH6dZbC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Wir implementieren in der Folge 2 Architekturen:\n",
        "\"\"\"\n",
        " Die 50dim 20LSTMs beenden ihre Sequenzen und kippen das Ergebnis in einen großen Vektor\n",
        "1. Nun verwenden wir den konkatenierten Vektor,\n",
        "2.\n",
        "\n",
        "\"\"\"\n",
        "#PS: Wenn das da oben konvergiert, bastle ich ein Teilmodell, das ich dann in einen Vektor stecke, den ich dann einfriere\n",
        "#Dieser Vektor wird dann in einem weiteren Modell als zusätzlicher Layer verwendet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P5OIMOQUkLIb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Reshape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PBe3mKUoXsPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1452
        },
        "outputId": "53b6bd80-31b6-403c-ce41-6fc9f2bf2a95"
      },
      "cell_type": "code",
      "source": [
        "#Version 2\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, Flatten\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, TimeDistributed, Bidirectional, CuDNNLSTM\n",
        "from keras.layers.merge import add\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences=Embedding(50491,300, weights=[weights])(sequence_input)\n",
        "x = Dropout(0.75)(embedded_sequences)\n",
        "xn = Bidirectional(CuDNNLSTM(128,return_sequences=True))(x)\n",
        "x = Dropout(0.75)(xn)\n",
        "x = Bidirectional(CuDNNLSTM(100,return_sequences=True))(x) # ich habe die beiden mal deutlich reduziert\n",
        "\n",
        "aux_inputs=[Input(shape=(20,), dtype=\"int32\") for i in range(MAX_SEQUENCE_LENGTH)]\n",
        "aux_embedding=Embedding(len(aux_tokenizer.word_index),30)\n",
        "aux_embedded=[aux_embedding(inp) for inp in aux_inputs]\n",
        "aux_lstm=CuDNNLSTM(200)#,return_sequences=True)\n",
        "aux_x = [Dropout(0.3)(aux_lstm(vals)) for vals in aux_embedded]\n",
        "dense=Dense(200)\n",
        "aux_x = [dense(vals) for vals in aux_x]\n",
        "x2=keras.layers.concatenate(aux_x) #Über welche Achse machen wir das denn?\n",
        "x2=Reshape((MAX_SEQUENCE_LENGTH,200))(x2)\n",
        "x2=Dropout(0.4)(x2)\n",
        "x2=CuDNNLSTM(200, return_sequences=True)(x2)\n",
        "x2=Bidirectional(CuDNNLSTM(200,return_sequences=True))(x2)\n",
        "x = keras.layers.concatenate([x, x2])\n",
        "#x=x2\n",
        "x = Dropout(0.5)(x)\n",
        "x = Bidirectional(CuDNNLSTM(256,return_sequences=True))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Bidirectional(CuDNNLSTM(128,return_sequences=True))(x)\n",
        "x = add([x,xn])\n",
        "preds = TimeDistributed(Dense(numoftags+1,activation=\"softmax\"))(x)\n",
        "\n",
        "model = Model([sequence_input]+aux_inputs, preds)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "hist=model.fit([X1]+auxseq, Y, epochs=100, batch_size=128, validation_split=0.1)\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14030 samples, validate on 1559 samples\n",
            "Epoch 1/100\n",
            "14030/14030 [==============================] - 60s 4ms/step - loss: 1.1316 - acc: 0.6505 - val_loss: 0.4452 - val_acc: 0.8726\n",
            "Epoch 2/100\n",
            "14030/14030 [==============================] - 30s 2ms/step - loss: 0.3483 - acc: 0.8919 - val_loss: 0.2242 - val_acc: 0.9282\n",
            "Epoch 3/100\n",
            "14030/14030 [==============================] - 30s 2ms/step - loss: 0.2347 - acc: 0.9249 - val_loss: 0.1916 - val_acc: 0.9400\n",
            "Epoch 4/100\n",
            "14030/14030 [==============================] - 30s 2ms/step - loss: 0.1981 - acc: 0.9368 - val_loss: 0.1710 - val_acc: 0.9446\n",
            "Epoch 5/100\n",
            "14030/14030 [==============================] - 30s 2ms/step - loss: 0.1761 - acc: 0.9437 - val_loss: 0.1633 - val_acc: 0.9477\n",
            "Epoch 6/100\n",
            "14030/14030 [==============================] - 30s 2ms/step - loss: 0.1603 - acc: 0.9490 - val_loss: 0.1539 - val_acc: 0.9518\n",
            "Epoch 7/100\n",
            "14030/14030 [==============================] - 30s 2ms/step - loss: 0.1482 - acc: 0.9529 - val_loss: 0.1498 - val_acc: 0.9533\n",
            "Epoch 8/100\n",
            "14030/14030 [==============================] - 30s 2ms/step - loss: 0.1380 - acc: 0.9561 - val_loss: 0.1425 - val_acc: 0.9546\n",
            "Epoch 9/100\n",
            "14030/14030 [==============================] - 30s 2ms/step - loss: 0.1299 - acc: 0.9587 - val_loss: 0.1392 - val_acc: 0.9564\n",
            "Epoch 10/100\n",
            "14030/14030 [==============================] - 30s 2ms/step - loss: 0.1229 - acc: 0.9606 - val_loss: 0.1409 - val_acc: 0.9556\n",
            "Epoch 11/100\n",
            "14030/14030 [==============================] - 30s 2ms/step - loss: 0.1168 - acc: 0.9622 - val_loss: 0.1380 - val_acc: 0.9563\n",
            "Epoch 12/100\n",
            "14030/14030 [==============================] - 30s 2ms/step - loss: 0.1101 - acc: 0.9645 - val_loss: 0.1367 - val_acc: 0.9569\n",
            "Epoch 13/100\n",
            "14030/14030 [==============================] - 30s 2ms/step - loss: 0.1040 - acc: 0.9660 - val_loss: 0.1361 - val_acc: 0.9569\n",
            "Epoch 14/100\n",
            "14030/14030 [==============================] - 30s 2ms/step - loss: 0.0995 - acc: 0.9676 - val_loss: 0.1414 - val_acc: 0.9550\n",
            "Epoch 15/100\n",
            "14030/14030 [==============================] - 30s 2ms/step - loss: 0.0946 - acc: 0.9692 - val_loss: 0.1378 - val_acc: 0.9568\n",
            "Epoch 16/100\n",
            "  128/14030 [..............................] - ETA: 28s - loss: 0.0992 - acc: 0.9652"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-f4b8b4d034ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0maux_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mauxseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "cloHcX1ogco0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "model.add(Conv1D(300, 3, padding='valid',activation='relu',strides=2))\n",
        "model.add(Conv1D(150, 3, padding='valid',activation='relu',strides=2))\n",
        "model.add(Conv1D(75, 3, padding='valid',activation='relu',strides=2))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X1T6omByna9A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Kombinieren wir das mal mit Proessor Everts Produkt und führen es auf dme englishcne Tagger aus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jbpCxUocihNL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3743
        },
        "outputId": "0e499461-1360-4f7e-8fe3-307e60fec444"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_195 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_196 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_197 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_198 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_199 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_200 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_201 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_202 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_203 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_204 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_205 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_206 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_207 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_208 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_209 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_210 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_211 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_212 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_213 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_214 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_24 (Embedding)        (None, 20, 30)       1514700     input_195[0][0]                  \n",
            "                                                                 input_196[0][0]                  \n",
            "                                                                 input_197[0][0]                  \n",
            "                                                                 input_198[0][0]                  \n",
            "                                                                 input_199[0][0]                  \n",
            "                                                                 input_200[0][0]                  \n",
            "                                                                 input_201[0][0]                  \n",
            "                                                                 input_202[0][0]                  \n",
            "                                                                 input_203[0][0]                  \n",
            "                                                                 input_204[0][0]                  \n",
            "                                                                 input_205[0][0]                  \n",
            "                                                                 input_206[0][0]                  \n",
            "                                                                 input_207[0][0]                  \n",
            "                                                                 input_208[0][0]                  \n",
            "                                                                 input_209[0][0]                  \n",
            "                                                                 input_210[0][0]                  \n",
            "                                                                 input_211[0][0]                  \n",
            "                                                                 input_212[0][0]                  \n",
            "                                                                 input_213[0][0]                  \n",
            "                                                                 input_214[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_7 (CuDNNLSTM)        (None, 200)          185600      embedding_24[0][0]               \n",
            "                                                                 embedding_24[1][0]               \n",
            "                                                                 embedding_24[2][0]               \n",
            "                                                                 embedding_24[3][0]               \n",
            "                                                                 embedding_24[4][0]               \n",
            "                                                                 embedding_24[5][0]               \n",
            "                                                                 embedding_24[6][0]               \n",
            "                                                                 embedding_24[7][0]               \n",
            "                                                                 embedding_24[8][0]               \n",
            "                                                                 embedding_24[9][0]               \n",
            "                                                                 embedding_24[10][0]              \n",
            "                                                                 embedding_24[11][0]              \n",
            "                                                                 embedding_24[12][0]              \n",
            "                                                                 embedding_24[13][0]              \n",
            "                                                                 embedding_24[14][0]              \n",
            "                                                                 embedding_24[15][0]              \n",
            "                                                                 embedding_24[16][0]              \n",
            "                                                                 embedding_24[17][0]              \n",
            "                                                                 embedding_24[18][0]              \n",
            "                                                                 embedding_24[19][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_200 (Dropout)           (None, 200)          0           cu_dnnlstm_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_201 (Dropout)           (None, 200)          0           cu_dnnlstm_7[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_202 (Dropout)           (None, 200)          0           cu_dnnlstm_7[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_203 (Dropout)           (None, 200)          0           cu_dnnlstm_7[3][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_204 (Dropout)           (None, 200)          0           cu_dnnlstm_7[4][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_205 (Dropout)           (None, 200)          0           cu_dnnlstm_7[5][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_206 (Dropout)           (None, 200)          0           cu_dnnlstm_7[6][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_207 (Dropout)           (None, 200)          0           cu_dnnlstm_7[7][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_208 (Dropout)           (None, 200)          0           cu_dnnlstm_7[8][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_209 (Dropout)           (None, 200)          0           cu_dnnlstm_7[9][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_210 (Dropout)           (None, 200)          0           cu_dnnlstm_7[10][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_211 (Dropout)           (None, 200)          0           cu_dnnlstm_7[11][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_212 (Dropout)           (None, 200)          0           cu_dnnlstm_7[12][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_213 (Dropout)           (None, 200)          0           cu_dnnlstm_7[13][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_214 (Dropout)           (None, 200)          0           cu_dnnlstm_7[14][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_215 (Dropout)           (None, 200)          0           cu_dnnlstm_7[15][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_216 (Dropout)           (None, 200)          0           cu_dnnlstm_7[16][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_217 (Dropout)           (None, 200)          0           cu_dnnlstm_7[17][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_218 (Dropout)           (None, 200)          0           cu_dnnlstm_7[18][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_219 (Dropout)           (None, 200)          0           cu_dnnlstm_7[19][0]              \n",
            "__________________________________________________________________________________________________\n",
            "input_194 (InputLayer)          (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_74 (Dense)                (None, 200)          40200       dropout_200[0][0]                \n",
            "                                                                 dropout_201[0][0]                \n",
            "                                                                 dropout_202[0][0]                \n",
            "                                                                 dropout_203[0][0]                \n",
            "                                                                 dropout_204[0][0]                \n",
            "                                                                 dropout_205[0][0]                \n",
            "                                                                 dropout_206[0][0]                \n",
            "                                                                 dropout_207[0][0]                \n",
            "                                                                 dropout_208[0][0]                \n",
            "                                                                 dropout_209[0][0]                \n",
            "                                                                 dropout_210[0][0]                \n",
            "                                                                 dropout_211[0][0]                \n",
            "                                                                 dropout_212[0][0]                \n",
            "                                                                 dropout_213[0][0]                \n",
            "                                                                 dropout_214[0][0]                \n",
            "                                                                 dropout_215[0][0]                \n",
            "                                                                 dropout_216[0][0]                \n",
            "                                                                 dropout_217[0][0]                \n",
            "                                                                 dropout_218[0][0]                \n",
            "                                                                 dropout_219[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_23 (Embedding)        (None, 20, 300)      15147300    input_194[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 4000)         0           dense_74[0][0]                   \n",
            "                                                                 dense_74[1][0]                   \n",
            "                                                                 dense_74[2][0]                   \n",
            "                                                                 dense_74[3][0]                   \n",
            "                                                                 dense_74[4][0]                   \n",
            "                                                                 dense_74[5][0]                   \n",
            "                                                                 dense_74[6][0]                   \n",
            "                                                                 dense_74[7][0]                   \n",
            "                                                                 dense_74[8][0]                   \n",
            "                                                                 dense_74[9][0]                   \n",
            "                                                                 dense_74[10][0]                  \n",
            "                                                                 dense_74[11][0]                  \n",
            "                                                                 dense_74[12][0]                  \n",
            "                                                                 dense_74[13][0]                  \n",
            "                                                                 dense_74[14][0]                  \n",
            "                                                                 dense_74[15][0]                  \n",
            "                                                                 dense_74[16][0]                  \n",
            "                                                                 dense_74[17][0]                  \n",
            "                                                                 dense_74[18][0]                  \n",
            "                                                                 dense_74[19][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_198 (Dropout)           (None, 20, 300)      0           embedding_23[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_7 (Reshape)             (None, 20, 200)      0           concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_35 (Bidirectional (None, 20, 256)      440320      dropout_198[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_220 (Dropout)           (None, 20, 200)      0           reshape_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_199 (Dropout)           (None, 20, 256)      0           bidirectional_35[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_8 (CuDNNLSTM)        (None, 20, 200)      321600      dropout_220[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_36 (Bidirectional (None, 20, 200)      286400      dropout_199[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_37 (Bidirectional (None, 20, 400)      643200      cu_dnnlstm_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 20, 600)      0           bidirectional_36[0][0]           \n",
            "                                                                 bidirectional_37[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_221 (Dropout)           (None, 20, 600)      0           concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_38 (Bidirectional (None, 20, 512)      1757184     dropout_221[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_222 (Dropout)           (None, 20, 512)      0           bidirectional_38[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_39 (Bidirectional (None, 20, 256)      657408      dropout_222[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 20, 256)      0           bidirectional_39[0][0]           \n",
            "                                                                 bidirectional_35[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_7 (TimeDistrib (None, 20, 17)       4369        add_2[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 20,998,281\n",
            "Trainable params: 20,998,281\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A2bT0jIVRW_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "a8e0f1ca-f119-4038-8edd-159516b993fe"
      },
      "cell_type": "code",
      "source": [
        "#Version 2 Tweaked? Mehr bilstms und mehr Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, Flatten\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, TimeDistributed, Bidirectional, CuDNNLSTM\n",
        "from keras.layers.merge import add\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences=Embedding(50491,300, weights=[weights])(sequence_input)\n",
        "x = Dropout(0.77)(embedded_sequences)\n",
        "xn = Bidirectional(CuDNNLSTM(128,return_sequences=True))(x)\n",
        "x = Dropout(0.77)(xn)\n",
        "x = Bidirectional(CuDNNLSTM(128,return_sequences=True))(x) # ich habe die beiden mal deutlich reduziert\n",
        "\n",
        "aux_inputs=[Input(shape=(20,), dtype=\"int32\") for i in range(MAX_SEQUENCE_LENGTH)]\n",
        "aux_embedding=Embedding(len(aux_tokenizer.word_index),30)\n",
        "aux_embedded=[aux_embedding(inp) for inp in aux_inputs]\n",
        "aux_lstm=Bidirectional(CuDNNLSTM(200))#,return_sequences=True)\n",
        "aux_x = [Dropout(0.4)(aux_lstm(vals)) for vals in aux_embedded]\n",
        "dense=Dense(200)\n",
        "aux_x = [dense(vals) for vals in aux_x]\n",
        "x2=keras.layers.concatenate(aux_x) #Über welche Achse machen wir das denn?\n",
        "x2=Reshape((MAX_SEQUENCE_LENGTH,200))(x2)\n",
        "x2=Dropout(0.6)(x2)\n",
        "x2=Bidirectional(CuDNNLSTM(200, return_sequences=True))(x2)\n",
        "x2=Dropout(0.6)(x2)\n",
        "x2=Bidirectional(CuDNNLSTM(200,return_sequences=True))(x2)\n",
        "x = keras.layers.concatenate([x, x2])\n",
        "#x=x2\n",
        "x = Dropout(0.6)(x)\n",
        "x = Bidirectional(CuDNNLSTM(256,return_sequences=True))(x)\n",
        "x = Dropout(0.55)(x)\n",
        "x = Bidirectional(CuDNNLSTM(128,return_sequences=True))(x)\n",
        "x = add([x,xn])\n",
        "preds = TimeDistributed(Dense(numoftags+1,activation=\"softmax\"))(x)\n",
        "\n",
        "model = Model([sequence_input]+aux_inputs, preds)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "hist=model.fit([X1]+auxseq, Y, epochs=25, batch_size=512, validation_split=0.1)\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14030 samples, validate on 1559 samples\n",
            "Epoch 1/25\n",
            "14030/14030 [==============================] - 59s 4ms/step - loss: 1.8645 - acc: 0.3994 - val_loss: 1.4587 - val_acc: 0.5486\n",
            "Epoch 2/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 1.2234 - acc: 0.6358 - val_loss: 0.8579 - val_acc: 0.7540\n",
            "Epoch 3/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.6901 - acc: 0.8062 - val_loss: 0.4522 - val_acc: 0.8755\n",
            "Epoch 4/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.4405 - acc: 0.8713 - val_loss: 0.3182 - val_acc: 0.9046\n",
            "Epoch 5/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.3228 - acc: 0.9029 - val_loss: 0.2508 - val_acc: 0.9267\n",
            "Epoch 6/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.2634 - acc: 0.9193 - val_loss: 0.2171 - val_acc: 0.9328\n",
            "Epoch 7/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.2294 - acc: 0.9290 - val_loss: 0.2186 - val_acc: 0.9304\n",
            "Epoch 8/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.2072 - acc: 0.9346 - val_loss: 0.1871 - val_acc: 0.9423\n",
            "Epoch 9/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.1896 - acc: 0.9400 - val_loss: 0.1800 - val_acc: 0.9440\n",
            "Epoch 10/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.1796 - acc: 0.9426 - val_loss: 0.1779 - val_acc: 0.9428\n",
            "Epoch 11/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.1685 - acc: 0.9460 - val_loss: 0.1672 - val_acc: 0.9465\n",
            "Epoch 12/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.1594 - acc: 0.9489 - val_loss: 0.1658 - val_acc: 0.9466\n",
            "Epoch 13/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.1517 - acc: 0.9510 - val_loss: 0.1596 - val_acc: 0.9485\n",
            "Epoch 14/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.1453 - acc: 0.9526 - val_loss: 0.1585 - val_acc: 0.9493\n",
            "Epoch 15/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.1394 - acc: 0.9547 - val_loss: 0.1540 - val_acc: 0.9515\n",
            "Epoch 16/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.1341 - acc: 0.9567 - val_loss: 0.1561 - val_acc: 0.9504\n",
            "Epoch 17/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.1280 - acc: 0.9580 - val_loss: 0.1519 - val_acc: 0.9521\n",
            "Epoch 18/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.1244 - acc: 0.9597 - val_loss: 0.1475 - val_acc: 0.9527\n",
            "Epoch 19/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.1190 - acc: 0.9616 - val_loss: 0.1483 - val_acc: 0.9532\n",
            "Epoch 20/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.1136 - acc: 0.9633 - val_loss: 0.1481 - val_acc: 0.9540\n",
            "Epoch 21/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.1109 - acc: 0.9638 - val_loss: 0.1467 - val_acc: 0.9535\n",
            "Epoch 22/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.1066 - acc: 0.9647 - val_loss: 0.1447 - val_acc: 0.9542\n",
            "Epoch 23/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.1022 - acc: 0.9667 - val_loss: 0.1467 - val_acc: 0.9531\n",
            "Epoch 24/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.0995 - acc: 0.9674 - val_loss: 0.1423 - val_acc: 0.9558\n",
            "Epoch 25/25\n",
            "14030/14030 [==============================] - 25s 2ms/step - loss: 0.0960 - acc: 0.9684 - val_loss: 0.1437 - val_acc: 0.9553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AQ3wVOqkY7ew",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZB0AuH8FR-2T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "27cda530-3f32-4660-c8b5-cdf165f817f5"
      },
      "cell_type": "code",
      "source": [
        "#Version 2 Tweaked? Mehr bilstms und mehr Dropout. Und ein bisschen komisches\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, Flatten\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, TimeDistributed, Bidirectional, CuDNNLSTM\n",
        "from keras.layers.merge import add\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences=Embedding(50491,300, weights=[weights])(sequence_input)\n",
        "x = Dropout(0.77)(embedded_sequences)\n",
        "xn = Bidirectional(CuDNNLSTM(128,return_sequences=True))(x)\n",
        "x = Dropout(0.77)(xn)\n",
        "x = Bidirectional(CuDNNLSTM(128,return_sequences=True))(x) # ich habe die beiden mal deutlich reduziert\n",
        "\n",
        "aux_inputs=[Input(shape=(20,), dtype=\"int32\") for i in range(MAX_SEQUENCE_LENGTH)]\n",
        "aux_embedding=Embedding(len(aux_tokenizer.word_index),30)\n",
        "aux_embedded=[aux_embedding(inp) for inp in aux_inputs]\n",
        "aux_lstm=Bidirectional(CuDNNLSTM(200,return_sequences=True))\n",
        "aux_x = [Dropout(0.5)(aux_lstm(vals)) for vals in aux_embedded]\n",
        "aux_lstme=Bidirectional(CuDNNLSTM(200))\n",
        "aux_x = [Dropout(0.5)(aux_lstme(vals)) for vals in aux_x]\n",
        "dense=Dense(200)\n",
        "aux_x = [dense(vals) for vals in aux_x]\n",
        "x2=keras.layers.concatenate(aux_x) #Über welche Achse machen wir das denn?\n",
        "x2=Reshape((MAX_SEQUENCE_LENGTH,200))(x2)\n",
        "x2=Dropout(0.6)(x2)\n",
        "x2=Bidirectional(CuDNNLSTM(200, return_sequences=True))(x2)\n",
        "x2=Dropout(0.6)(x2)\n",
        "x2=Bidirectional(CuDNNLSTM(200,return_sequences=True))(x2)\n",
        "#x = keras.layers.concatenate([x, x2])\n",
        "x=x2 #Nun trainieren wir das Modell allein auf den Repräsentationen \n",
        "x = Dropout(0.6)(x)\n",
        "x = Bidirectional(CuDNNLSTM(256,return_sequences=True))(x)\n",
        "x = Dropout(0.55)(x)\n",
        "x = Bidirectional(CuDNNLSTM(128,return_sequences=True))(x)\n",
        "#x = add([x,xn])\n",
        "preds = TimeDistributed(Dense(numoftags+1,activation=\"softmax\"))(x)\n",
        "\n",
        "model = Model([sequence_input]+aux_inputs, preds)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "histi=model.fit([X1]+auxseq, Y, epochs=30, batch_size=256, validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14030 samples, validate on 1559 samples\n",
            "Epoch 1/30\n",
            "14030/14030 [==============================] - 105s 8ms/step - loss: 2.3705 - acc: 0.2709 - val_loss: 2.1109 - val_acc: 0.3596\n",
            "Epoch 2/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 2.1830 - acc: 0.3164 - val_loss: 1.9581 - val_acc: 0.3802\n",
            "Epoch 3/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.9483 - acc: 0.3630 - val_loss: 1.7870 - val_acc: 0.4241\n",
            "Epoch 4/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.8707 - acc: 0.3760 - val_loss: 1.7356 - val_acc: 0.4326\n",
            "Epoch 5/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.8281 - acc: 0.3874 - val_loss: 1.6722 - val_acc: 0.4499\n",
            "Epoch 6/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.6854 - acc: 0.4246 - val_loss: 1.5765 - val_acc: 0.4680\n",
            "Epoch 7/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.6216 - acc: 0.4381 - val_loss: 1.6359 - val_acc: 0.4476\n",
            "Epoch 8/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.5884 - acc: 0.4496 - val_loss: 1.4629 - val_acc: 0.5148\n",
            "Epoch 9/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.4424 - acc: 0.5106 - val_loss: 1.3277 - val_acc: 0.5430\n",
            "Epoch 10/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.3731 - acc: 0.5300 - val_loss: 1.3021 - val_acc: 0.5641\n",
            "Epoch 11/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.3064 - acc: 0.5517 - val_loss: 1.2115 - val_acc: 0.5853\n",
            "Epoch 12/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.2413 - acc: 0.5730 - val_loss: 1.1889 - val_acc: 0.5949\n",
            "Epoch 13/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.1957 - acc: 0.5887 - val_loss: 1.1170 - val_acc: 0.6144\n",
            "Epoch 14/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.1401 - acc: 0.6067 - val_loss: 1.1359 - val_acc: 0.6107\n",
            "Epoch 15/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.1024 - acc: 0.6189 - val_loss: 1.0539 - val_acc: 0.6389\n",
            "Epoch 16/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.0687 - acc: 0.6327 - val_loss: 1.0366 - val_acc: 0.6426\n",
            "Epoch 17/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.0272 - acc: 0.6455 - val_loss: 1.0080 - val_acc: 0.6527\n",
            "Epoch 18/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 1.0006 - acc: 0.6542 - val_loss: 0.9468 - val_acc: 0.6753\n",
            "Epoch 19/30\n",
            "14030/14030 [==============================] - 61s 4ms/step - loss: 0.9681 - acc: 0.6657 - val_loss: 0.9560 - val_acc: 0.6677\n",
            "Epoch 20/30\n",
            " 8704/14030 [=================>............] - ETA: 22s - loss: 0.9515 - acc: 0.6709"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}